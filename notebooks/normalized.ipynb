{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIC-HEAP Cirta Particle Classification Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/train/combined.pkl'\n",
    "test_path = '../data/test/data_test_file.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, 'rb') as f:\n",
    "    training_data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes2name = {11: 'electron', 13: 'muon', 211: 'pion', 321: 'kaon', 2212: 'proton'}\n",
    "classes2int = {11:0, 13:1, 211:2, 321:3, 2212:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(data):\n",
    "    fig = plt.figure(figsize=(25, 4))\n",
    "    \n",
    "    for i in np.arange(20):\n",
    "        ax = fig.add_subplot(2, 10, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(data[0][i], cmap='gray')\n",
    "        ax.set_title(classes2name[data[1][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**separate images from labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1176475)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.zeros((1176475, 10, 10))\n",
    "\n",
    "for i in range(1176475):\n",
    "    train_images[i,:] = training_data[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.zeros((1176475))\n",
    "\n",
    "for i in range(1176475):\n",
    "    train_labels[i] = classes2int[training_data[1][i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**normalize the images**\n",
    "\n",
    "Mean subtraction removes the mean of the dataset form each data point. \n",
    "\n",
    "<!--Then we normalize by dividing each zero-centred dimension by its standard deviation. This makes convergence faster while training the network. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.0, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max, min = np.max(train_images), np.min(train_images)\n",
    "max, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (train_images - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After-> min value: 0.0  max value: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'After-> min value: {np.min(train_images)}  max value: {np.max(train_images)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = torch.from_numpy(train_images), torch.from_numpy(train_labels.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images[:, None, :, :] # insert empty dimension at the channels axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        #out = torch.relu(self.bn2(self.conv2(out)))\n",
    "        out = out.view(-1, 32 * 5 * 5)\n",
    "        out = torch.log_softmax(self.fc1(out), dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "training_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20 | Training loss: 0.715 | Accuracy: 77.002\n",
      "Epoch: 2/20 | Training loss: 0.713 | Accuracy: 77.014\n",
      "Epoch: 3/20 | Training loss: 0.713 | Accuracy: 77.013\n",
      "Epoch: 4/20 | Training loss: 0.713 | Accuracy: 77.014\n",
      "Epoch: 5/20 | Training loss: 0.713 | Accuracy: 77.014\n",
      "Epoch: 6/20 | Training loss: 0.713 | Accuracy: 77.013\n",
      "Epoch: 7/20 | Training loss: 0.713 | Accuracy: 77.014\n",
      "Epoch: 8/20 | Training loss: 0.713 | Accuracy: 77.013\n",
      "Epoch: 9/20 | Training loss: 0.713 | Accuracy: 77.013\n",
      "Epoch: 10/20 | Training loss: 0.714 | Accuracy: 77.014\n",
      "Epoch: 11/20 | Training loss: 0.714 | Accuracy: 77.014\n",
      "Epoch: 12/20 | Training loss: 0.714 | Accuracy: 77.013\n",
      "Epoch: 13/20 | Training loss: 0.714 | Accuracy: 77.014\n",
      "Epoch: 14/20 | Training loss: 0.714 | Accuracy: 77.013\n",
      "Epoch: 15/20 | Training loss: 0.714 | Accuracy: 77.014\n",
      "Epoch: 16/20 | Training loss: 0.714 | Accuracy: 77.014\n",
      "Epoch: 17/20 | Training loss: 0.714 | Accuracy: 77.015\n",
      "Epoch: 18/20 | Training loss: 0.714 | Accuracy: 77.013\n",
      "Epoch: 19/20 | Training loss: 0.714 | Accuracy: 77.013\n",
      "Epoch: 20/20 | Training loss: 0.714 | Accuracy: 77.014\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    running_train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device, dtype=torch.float), labels.to(device)\n",
    "        \n",
    "        # zero out the gradients of the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        log_ps = model(images)\n",
    "        # find the loss\n",
    "        train_loss = criterion(log_ps, labels)\n",
    "        # backpropagate\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_train_loss += train_loss.item()\n",
    "        # find accuracy\n",
    "        probs = torch.exp(log_ps)\n",
    "        _, top_class = probs.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        train_acc += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "    else:\n",
    "        # print stats\n",
    "        print(f'Epoch: {epoch}/{n_epochs} | Training loss: {running_train_loss/len(train_loader):.3f} | '\n",
    "              f'Accuracy: {train_acc/len(train_loader)*100:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
